{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filename_format_log(file_path, \n",
    "                        logfile = '../assets/file_log.txt', \n",
    "                        now = round(time.time()), \n",
    "                        file_description = None): \n",
    "   \n",
    "    try:\n",
    "        ext = re.search('(?<!^)(?<!\\.)\\.(?!\\.)', file_path).start() \n",
    "    except:\n",
    "        raise NameError('Please enter a relative path with a file extension.') \n",
    "    \n",
    "    stamp = re.search('(?<!^)(?<!\\.)[a-z]+_[0-z]+(?=\\.)', file_path).start()\n",
    "    formatted_name = f'{file_path[:stamp]}{now}_{file_path[stamp:]}'  \n",
    "    if not file_description:\n",
    "        file_description = f'Saved at: {time.asctime(time.gmtime(now))}'\n",
    "    with open(logfile, 'a+') as f:\n",
    "        f.write(f'{formatted_name}: {file_description}\\n')\n",
    "    return formatted_name, now, file_description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def con_cur_to_db(dbname=DBNAME, dict_cur=None):\n",
    "    con = pg2.connect(host=IP_ADDRESS,\n",
    "                  dbname=dbname,\n",
    "                  user=USER,\n",
    "                  password=PASSWORD)\n",
    "    if dict_cur:\n",
    "        cur = con.cursor(cursor_factory=RealDictCursor)\n",
    "    else:\n",
    "        cur = con.cursor()\n",
    "    return con, cur\n",
    "    \n",
    "def execute_query(query, dbname=DBNAME, dict_cur=None, command=False):\n",
    "    con, cur = con_cur_to_db(dbname, dict_cur)\n",
    "    cur.execute(f'{query}')\n",
    "    if not command:\n",
    "        data = cur.fetchall()\n",
    "        con.close()\n",
    "        return data\n",
    "    con.commit() #sends to server\n",
    "    con.close() #closes server connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def insert_playlist_info(track_dict):\n",
    "    con, cur = con_cur_to_db()\n",
    "    \n",
    "    columns = track_dict.keys()\n",
    "    values = [track_dict[column] for column in columns]\n",
    "\n",
    "    insert_statement = 'INSERT INTO track_list (%s) VALUES %s;'\n",
    "    \n",
    "    try:\n",
    "        cur.execute(insert_statement, (AsIs(','.join(columns)), tuple(values)))\n",
    "    \n",
    "    except pg2.IntegrityError:\n",
    "        print(\"Duplicate track. Skipping:\")\n",
    "        print(tuple(values))\n",
    "\n",
    "    con.commit()\n",
    "    con.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def insert_lyrics(lyrics, track_id):\n",
    "    con, cur = con_cur_to_db()\n",
    "    \n",
    "    insert_statement = f\"UPDATE track_list SET lyrics = {Json(lyrics)} WHERE track_id = '{track_id}';\" \n",
    "    \n",
    "    try:\n",
    "        cur.execute(insert_statement)\n",
    "\n",
    "    except pg2.IntegrityError:\n",
    "        print(\"Lyrics already added. Skipping:\")\n",
    "        print(track_id)\n",
    "    \n",
    "    except:\n",
    "        print(\"Upload error. Skipping:\")\n",
    "        print(track_id)\n",
    "        \n",
    "    con.commit()\n",
    "    con.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_playlist_tracks(category_id='romance', country='us', limit=50, cycles=10, offset=0):\n",
    "\n",
    "    fin_cycles = 0\n",
    "    \n",
    "    while fin_cycles < cycles:\n",
    "        \n",
    "        playlists = sp.category_playlists(category_id=category_id, country=country, limit=limit, offset=offset)\n",
    "\n",
    "        offset = offset + len(playlists['playlists']['items'])\n",
    "\n",
    "        for playlist in playlists['playlists']['items']:\n",
    "            playlist_id = playlist['id']\n",
    "            playlist_name = playlist['name']\n",
    "            playlist_owner = playlist['owner']['id']\n",
    "\n",
    "            tracks = sp.user_playlist_tracks(user = playlist_owner, \n",
    "                                             playlist_id = playlist_id) \n",
    "\n",
    "            for track in tracks['items']:\n",
    "                try:\n",
    "                    track_dict = {\n",
    "                        'track_id' : track['track']['id'],\n",
    "                        'playlist_id' : playlist_id,\n",
    "                        'track_name' : track['track']['name'],\n",
    "                        'artist_name' : track['track']['artists'][0]['name'],\n",
    "                        'album_name' : track['track']['album']['name'],\n",
    "                        'playlist_name' : playlist_name,\n",
    "                        'playlist_owner' : playlist_owner\n",
    "                    }\n",
    "\n",
    "                    insert_playlist_info(track_dict)\n",
    "                \n",
    "                except TypeError:\n",
    "                    print(f'Missing track info for track in {playlist_id}. Skipping track.')\n",
    "                    \n",
    "            print(f'Uploaded {playlist_name} playlist to SQLdb')\n",
    "\n",
    "        print(f'Finished uploading {offset} playlists in {category_id} category')\n",
    "        \n",
    "        fin_cycles += 1\n",
    "    \n",
    "    print(f'Finished uploading cycle: {fin_cycles}')\n",
    "    print(f'Current offset: {offset}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def request_song_info(song_title, artist_name):\n",
    "    search_url = 'https://api.genius.com/search'  \n",
    "    data = {'q': song_title + ' ' + artist_name}\n",
    "    headers = {'Authorization': 'Bearer ' + 'Q1xs6KCZB77dD_ZQEub53VCWrqrrNW8xWfMrrrgfj3yNWHLut1Cg-TufGpvVAt2E'}\n",
    "    \n",
    "    try:\n",
    "        response = requests.get(search_url, data=data, headers=headers)\n",
    "        json = response.json()\n",
    "\n",
    "    except requests.exceptions.ConnectionError: \n",
    "        print(f'*****Connection error for {artist_name}, {song_title}*****')\n",
    "        print('Retrying connection')\n",
    "        \n",
    "        session = requests.Session()\n",
    "        retry = Retry(connect=3, backoff_factor=0.5)\n",
    "        adapter = HTTPAdapter(max_retries=retry)\n",
    "        session.mount('http://', adapter)\n",
    "        session.mount('https://', adapter)\n",
    "\n",
    "        session.get(search_url, data=data, headers=headers)\n",
    "        \n",
    "    for hit in json['response']['hits']:\n",
    "        if (song_title.lower() in hit['result']['title'].lower()) & (artist_name.lower() in hit['result']['primary_artist']['name'].lower()): \n",
    "            song_url = hit['result']['url']\n",
    "            print(song_url)\n",
    "            page = requests.get(song_url)\n",
    "            html = BeautifulSoup(page.text, 'html.parser')\n",
    "            lyrics = html.find('div', class_='lyrics').get_text()\n",
    "\n",
    "            return lyrics\n",
    "\n",
    "        if (song_title.lower() in hit['result']['title'].lower()) | (artist_name.lower() in hit['result']['primary_artist']['name'].lower()): \n",
    "            song_url = hit['result']['url']\n",
    "            print(song_url)\n",
    "            page = requests.get(song_url)\n",
    "            html = BeautifulSoup(page.text, 'html.parser')\n",
    "            lyrics = html.find('div', class_='lyrics').get_text()\n",
    "\n",
    "            return lyrics\n",
    "        \n",
    "    else:\n",
    "        print(f'{song_title}, {artist_name} not found')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_genius_lyrics(df=track_df):\n",
    "    \n",
    "    for ix, row in df.iterrows():\n",
    "        track_id = str(ix)\n",
    "        song_title = row['track_name'].lower()\n",
    "        artist_name = row['artist_name']\n",
    "    \n",
    "        if (row['lyrics'] == None):\n",
    "            song_title = re.sub('(^|)((?<=)\\s-.+|\\s\\(.+\\)|(\\ssoundtrack)|\\s(\\\".+\\\"))','', song_title) \n",
    "            song_title = re.sub('(^|)((\\sremastered)|(\\sremaster)|(\\s\\d{4})|(\\w+\\sversion))','', song_title)\n",
    "            song_title = re.sub('(^|)((\\w+\\s+edit)|(\\sspotify.+)|(\\sat\\sspotify.+))','', song_title)\n",
    "            song_title = re.sub('\\s(feat\\..+)','', song_title)\n",
    "\n",
    "            lyrics = request_song_info(song_title=song_title, artist_name=artist_name)\n",
    "\n",
    "            try:\n",
    "                if len(lyrics) > 100:\n",
    "                    insert_lyrics(lyrics, track_id)\n",
    "                    print(f'Uploaded lyrics for {track_id}, {song_title}')\n",
    "                    time.sleep(.5)\n",
    "\n",
    "                else:\n",
    "                    print(f'*****Lyrics look short. Retry {track_id}, {song_title}*****')\n",
    "\n",
    "            except TypeError:\n",
    "                print(f'*****No lyrics for {track_id}, {song_title}*****')\n",
    "        \n",
    "    return 'Finished uploading tracks to SQLdb'"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
