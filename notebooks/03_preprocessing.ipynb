{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook 03: Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install psycopg2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.2.4\n"
     ]
    }
   ],
   "source": [
    "print(keras.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.12.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/opt/conda/lib/python3.6/site-packages/psycopg2/__init__.py:144: UserWarning: The psycopg2 wheel package will be renamed from release 2.8; in order to keep installing from binary please use \"pip install psycopg2-binary\" instead. For details see: <http://initd.org/psycopg/docs/install.html#binary-install-from-pypi>.\n",
      "  \"\"\")\n"
     ]
    }
   ],
   "source": [
    "import json, time, re, string, keras, adanet\n",
    "import pandas as pd\n",
    "import psycopg2 as pg2\n",
    "import numpy as np\n",
    "\n",
    "from psycopg2.extras import RealDictCursor, Json\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding, LSTM\n",
    "from keras.utils.np_utils import to_categorical\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "%run ../assets/sql_cred.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filename_format_log(file_path, \n",
    "                        logfile = '../assets/file_log.txt', \n",
    "                        now = round(time.time()), \n",
    "                        file_description = None): \n",
    "   \n",
    "    try:\n",
    "        ext = re.search('(?<!^)(?<!\\.)\\.(?!\\.)', file_path).start() \n",
    "    except:\n",
    "        raise NameError('Please enter a relative path with a file extension.') \n",
    "    \n",
    "    stamp = re.search('(?<!^)(?<!\\.)[a-z]+_[0-z]+(?=\\.)', file_path).start()\n",
    "    formatted_name = f'{file_path[:stamp]}{now}_{file_path[stamp:]}'  \n",
    "    if not file_description:\n",
    "        file_description = f'Saved at: {time.asctime(time.gmtime(now))}'\n",
    "    with open(logfile, 'a+') as f:\n",
    "        f.write(f'{formatted_name}: {file_description}\\n')\n",
    "    return formatted_name, now, file_description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def con_cur_to_db(dbname=DBNAME, dict_cur=None):\n",
    "    con = pg2.connect(host=IP_ADDRESS,\n",
    "                  dbname=dbname,\n",
    "                  user=USER,\n",
    "                  password=PASSWORD)\n",
    "    if dict_cur:\n",
    "        cur = con.cursor(cursor_factory=RealDictCursor)\n",
    "    else:\n",
    "        cur = con.cursor()\n",
    "    return con, cur\n",
    "    \n",
    "def execute_query(query, dbname=DBNAME, dict_cur=None, command=False):\n",
    "    con, cur = con_cur_to_db(dbname, dict_cur)\n",
    "    cur.execute(f'{query}')\n",
    "    if not command:\n",
    "        data = cur.fetchall()\n",
    "        con.close()\n",
    "        return data\n",
    "    con.commit() #sends to server\n",
    "    con.close() #closes server connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "lyric_df = pd.read_csv('../assets/1548873539_clean_lyrics.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lyrics</th>\n",
       "      <th>clean_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\\n\\nIf your needle is near\\nNeedle is near\\nYo...</td>\n",
       "      <td>if your needle is near \\n needle is near \\n yo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\\n\\n[Verse 1]\\nBrown skin girl on the other si...</td>\n",
       "      <td>brown skin girl on the other side of the room ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\\n\\n[Verse 1]\\nIt's simple, I love it\\nHaving ...</td>\n",
       "      <td>its simple i love it \\n having you near me hav...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\\n\\n[Intro: Whistling]\\n\\n[Verse 1]\\nA great b...</td>\n",
       "      <td>a great big bang and dinosaurs \\n fiery rainin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\\n\\n[Verse 1]\\nIsn't she lovely\\nIsn't she won...</td>\n",
       "      <td>isnt she lovely \\n isnt she wonderful \\n isnt ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              lyrics  \\\n",
       "0  \\n\\nIf your needle is near\\nNeedle is near\\nYo...   \n",
       "1  \\n\\n[Verse 1]\\nBrown skin girl on the other si...   \n",
       "2  \\n\\n[Verse 1]\\nIt's simple, I love it\\nHaving ...   \n",
       "3  \\n\\n[Intro: Whistling]\\n\\n[Verse 1]\\nA great b...   \n",
       "4  \\n\\n[Verse 1]\\nIsn't she lovely\\nIsn't she won...   \n",
       "\n",
       "                                          clean_text  \n",
       "0  if your needle is near \\n needle is near \\n yo...  \n",
       "1  brown skin girl on the other side of the room ...  \n",
       "2  its simple i love it \\n having you near me hav...  \n",
       "3  a great big bang and dinosaurs \\n fiery rainin...  \n",
       "4  isnt she lovely \\n isnt she wonderful \\n isnt ...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lyric_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "lyric_df = lyric_df.drop(index=[193], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lyrics</th>\n",
       "      <th>clean_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1800</td>\n",
       "      <td>1800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>1800</td>\n",
       "      <td>1800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>\\n\\n[Intro]\\nMy life is brilliant\\n\\n[Verse 1]...</td>\n",
       "      <td>caught me at the right time baby oh \\n i was a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   lyrics  \\\n",
       "count                                                1800   \n",
       "unique                                               1800   \n",
       "top     \\n\\n[Intro]\\nMy life is brilliant\\n\\n[Verse 1]...   \n",
       "freq                                                    1   \n",
       "\n",
       "                                               clean_text  \n",
       "count                                                1800  \n",
       "unique                                               1800  \n",
       "top     caught me at the right time baby oh \\n i was a...  \n",
       "freq                                                    1  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lyric_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:1: UserWarning: This pattern has match groups. To actually get the groups, use str.extract.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lyrics</th>\n",
       "      <th>clean_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>\\n\\n3/3\\nBoy Rex - The Bloodmonths - 8/8\\nJoey...</td>\n",
       "      <td>boy rex  the bloodmonths   \\n joey fatts  ill ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>\\n\\n[Verse 1]\\nJenny, Jenny, who can I turn to...</td>\n",
       "      <td>jenny jenny who can i turn to \\n you give me s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>\\n\\n[NEW]  1. TWICE - What Is Love?\\n[NEW] 2. ...</td>\n",
       "      <td>twice  what is love \\n   exocbx  blooming day ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>260</th>\n",
       "      <td>\\n\\n[Verse 1]:\\nElectric lights\\nBlow my mind\\...</td>\n",
       "      <td>electric lights \\n blow my mind \\n i feel alri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>552</th>\n",
       "      <td>\\n\\nBaby, baby yea\\nYou run on my mind yea\\nSa...</td>\n",
       "      <td>baby baby yea \\n you run on my mind yea \\n sam...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>938</th>\n",
       "      <td>\\n\\n[Verse 1]\\nThere are two of us on the run\\...</td>\n",
       "      <td>there are two of us on the run \\n going so fas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>960</th>\n",
       "      <td>\\n\\n[Verse 1]\\nYou're my baby, my lover, my la...</td>\n",
       "      <td>youre my baby my lover my lady \\n all night yo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1106</th>\n",
       "      <td>\\n\\nORIGINALTracklist1.  Let's Go Crazy\\n2.  T...</td>\n",
       "      <td>originaltracklist  lets go crazy \\n   take me ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1169</th>\n",
       "      <td>\\n\\n[Intro-Live Acoustic]\\nKnow your place amo...</td>\n",
       "      <td>know your place among the dark arms of the woo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1495</th>\n",
       "      <td>\\n\\n[Verse 1]\\nIt was a day\\nJust like any oth...</td>\n",
       "      <td>it was a day \\n just like any other day \\n i w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1545</th>\n",
       "      <td>\\n\\n[Intro: Too $hort]\\nYou know, it's a hard ...</td>\n",
       "      <td>you know its a hard pill to swallow \\n when th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1572</th>\n",
       "      <td>\\n\\n[Verse 1]\\nWrapped up, so consumed by\\nAll...</td>\n",
       "      <td>wrapped up so consumed by \\n all this hurt \\n ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1688</th>\n",
       "      <td>\\n\\n[Intro: Britt Nicole]\\nIt feels like a tea...</td>\n",
       "      <td>it feels like a tear in my heart \\n like a par...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1768</th>\n",
       "      <td>\\n\\nहाथ में रात ये बाकी है\\nबात नापाक वफ़ा की ह...</td>\n",
       "      <td>bang like a drum work my body \\n   im incharge...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 lyrics  \\\n",
       "31    \\n\\n3/3\\nBoy Rex - The Bloodmonths - 8/8\\nJoey...   \n",
       "142   \\n\\n[Verse 1]\\nJenny, Jenny, who can I turn to...   \n",
       "195   \\n\\n[NEW]  1. TWICE - What Is Love?\\n[NEW] 2. ...   \n",
       "260   \\n\\n[Verse 1]:\\nElectric lights\\nBlow my mind\\...   \n",
       "552   \\n\\nBaby, baby yea\\nYou run on my mind yea\\nSa...   \n",
       "938   \\n\\n[Verse 1]\\nThere are two of us on the run\\...   \n",
       "960   \\n\\n[Verse 1]\\nYou're my baby, my lover, my la...   \n",
       "1106  \\n\\nORIGINALTracklist1.  Let's Go Crazy\\n2.  T...   \n",
       "1169  \\n\\n[Intro-Live Acoustic]\\nKnow your place amo...   \n",
       "1495  \\n\\n[Verse 1]\\nIt was a day\\nJust like any oth...   \n",
       "1545  \\n\\n[Intro: Too $hort]\\nYou know, it's a hard ...   \n",
       "1572  \\n\\n[Verse 1]\\nWrapped up, so consumed by\\nAll...   \n",
       "1688  \\n\\n[Intro: Britt Nicole]\\nIt feels like a tea...   \n",
       "1768  \\n\\nहाथ में रात ये बाकी है\\nबात नापाक वफ़ा की ह...   \n",
       "\n",
       "                                             clean_text  \n",
       "31    boy rex  the bloodmonths   \\n joey fatts  ill ...  \n",
       "142   jenny jenny who can i turn to \\n you give me s...  \n",
       "195   twice  what is love \\n   exocbx  blooming day ...  \n",
       "260   electric lights \\n blow my mind \\n i feel alri...  \n",
       "552   baby baby yea \\n you run on my mind yea \\n sam...  \n",
       "938   there are two of us on the run \\n going so fas...  \n",
       "960   youre my baby my lover my lady \\n all night yo...  \n",
       "1106  originaltracklist  lets go crazy \\n   take me ...  \n",
       "1169  know your place among the dark arms of the woo...  \n",
       "1495  it was a day \\n just like any other day \\n i w...  \n",
       "1545  you know its a hard pill to swallow \\n when th...  \n",
       "1572  wrapped up so consumed by \\n all this hurt \\n ...  \n",
       "1688  it feels like a tear in my heart \\n like a par...  \n",
       "1768  bang like a drum work my body \\n   im incharge...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lyric_df[lyric_df['clean_text'].str.contains(r'(\\s{6,})')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "lyric_df = lyric_df.drop(index=1768, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_sequence(text, sequence_length = 7, output_length = 4):\n",
    "    \n",
    "    X, y = [], []\n",
    "    \n",
    "    split_text = re.split('(\\n)|(\\[.+\\])|\\s', text)\n",
    "    split_text = list(filter(None, split_text))\n",
    "    split_text = text\n",
    "    \n",
    "    for i in range(len(split_text) - sequence_length):\n",
    "        X.append(split_text[i:i + sequence_length])\n",
    "        y.append(split_text[i + sequence_length:i + sequence_length + output_length])\n",
    "        \n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_lyrics(df, lyrics_col, seq_len, output_len, save_tokenizer='../assets/tokenizer.pkl'):\n",
    "    X = []\n",
    "    y = []\n",
    "    \n",
    "    corpus = []\n",
    "    \n",
    "    print('Processing lyrics...')\n",
    "    for _, track in df[lyrics_col].iterrows():\n",
    "        lyrics = track[0]\n",
    "        lyrics_spaced = re.sub(r'( +)', ' ', lyrics)\n",
    "        lyrics_split = lyrics_spaced.split(' ')\n",
    "        corpus.extend(lyrics_split)\n",
    "                \n",
    "        for i in range(len(lyrics_split) - seq_len):\n",
    "            X.append(lyrics_split[i:i + seq_len])\n",
    "            y.extend(lyrics_split[i + seq_len:i + seq_len + output_len])\n",
    "            \n",
    "    print('Fitting Tokenizer...')\n",
    "    tokenizer = Tokenizer(oov_token=0)\n",
    "    tokenizer.filters = tokenizer.filters.replace('\\n', '')\n",
    "    tokenizer.fit_on_texts(corpus)\n",
    "\n",
    "    vocab_size = len(tokenizer.word_index) + 1\n",
    "        \n",
    "    print(f'Vocab size = {vocab_size}')\n",
    "#         formatted_name, now, file_description= filename_format_log(f'{save_tokenizer}')\n",
    "\n",
    "#         with open(formatted_name, 'wb+') as f:\n",
    "#             pickle.dump(tokenizer, f)\n",
    "#         print(f'Tokenizer saved to {formatted_name}.')          \n",
    "\n",
    "    print('Indexing sequences...')\n",
    "    X_indexed = [[tokenizer.texts_to_sequences([word])[0] for word in row] for row in X]\n",
    "    y_indexed = [tokenizer.texts_to_sequences([word])[0] for word in y]\n",
    "    print('Reshaping and converting to Categorical...')\n",
    "    X_reshape = np.reshape(X_indexed, (len(X_indexed), seq_len, 1))\n",
    " \n",
    "    y_cat = to_categorical(y_indexed)\n",
    "    \n",
    "    print('Lyrics successfully tokenized, sequenced, and indexed.')\n",
    "    return X_reshape, y_cat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "lyric_df['cleaner_text'] = lyric_df['clean_text'].map(lambda x: re.sub(r'( +)', ' ', x).split(' '))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[corpus.add(word) for song in lyric_df['clean_text'].map(lambda x: re.sub(r'( +)', ' ', x).split(' ')).values for word in song];"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "seq_len, output_len = 4, 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "def sequencer(lyrics_split, seq_len=4, output_len=1):\n",
    "    X, y = [], []\n",
    "    for i in range(len(lyrics_split) - seq_len):\n",
    "        X.append(lyrics_split[i:i + seq_len])\n",
    "        y.extend(lyrics_split[i + seq_len:i + seq_len + output_len])\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "foo = pd.DataFrame([1,2,3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "result = lyric_df.cleaner_text.map(sequencer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "result[0][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "lyrics_split[i + 4:i + 4 + 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing lyrics...\n",
      "Fitting Tokenizer...\n",
      "Vocab size = 13470\n",
      "Indexing sequences...\n",
      "Reshaping and converting to Categorical...\n",
      "Lyrics successfully tokenized, sequenced, and indexed.\n"
     ]
    }
   ],
   "source": [
    "X, y = tokenize_lyrics(df=lyric_df,\n",
    "                lyrics_col=['clean_text'],\n",
    "                seq_len=4,\n",
    "                output_len=1,\n",
    "                save_tokenizer='../assets/tokenizer.pkl'\n",
    "               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(576641, 4, 1)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(576641, 13470)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(32, input_shape=(X_train.shape[1], X_test.shape[2])))\n",
    "model.add(Dense(100, activation='relu'))\n",
    "model.add(Dense(y.shape[1], activation='softmax'))\n",
    "model.compile(\n",
    "    loss = 'categorical_crossentropy',\n",
    "    optimizer = 'adam',\n",
    "    metrics = ['accuracy'],\n",
    ")\n",
    "\n",
    "history = model.fit (\n",
    "    X_train, y_train,\n",
    "    epochs = 150,\n",
    "    batch_size = 2500,\n",
    "    verbose = 1,\n",
    "    \n",
    ")\n",
    "\n",
    "# formatted_name, now, file_description= filename_format_log('../assets/LSTM_Model.pkl')\n",
    "\n",
    "# with open(formatted_name, 'wb+') as f:\n",
    "#     pickle.dump(model, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(ncols=2, nrows=1, figsize=(18,6))\n",
    "\n",
    "ax[0].plot(history.history['loss'])\n",
    "ax[0].set_title(\"Loss\", fontsize=15);\n",
    "ax[0].set_xlabel(\"epochs\",fontsize=15);\n",
    "\n",
    "ax[1].plot(history.history['acc'])\n",
    "ax[1].set_title(\"Accuracy\",fontsize=15);\n",
    "ax[1].set_xlabel(\"epochs\",fontsize=15);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_lyrics(seed, model=model, seq_len=4, song_len=50):\n",
    "    seed_clean = seed.lower().split(' ')\n",
    "    doc = []\n",
    "\n",
    "    while len(doc) < song_len:\n",
    "        text = [seed_clean]\n",
    "        sequence = [tokenizer.texts_to_sequences([word])[0] for word in text]\n",
    "        pad_sequence = pad_sequences(sequence, maxlen=seq_len, truncating='pre')\n",
    "        sequence_reshape = np.reshape(pad_sequence, (len(test_indexed), 4, 1))\n",
    "\n",
    "        yhat = model.predict_classes(sequence_reshape, verbose=0)\n",
    "\n",
    "        for word, index in tokenizer.word_index.items():\n",
    "            if index == yhat:\n",
    "                seed_clean.append(word)\n",
    "                doc.append(word)\n",
    "\n",
    "    return ' '.join(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lyrics = generate_lyrics('needles are for lovers', song_len=150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lyrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# formatted_name, now, file_description= filename_format_log(file_path = '../assets/lyric_X74.pkl')\n",
    "\n",
    "# with open(formatted_name, 'wb+') as f:\n",
    "#     pickle.dump(X, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# formatted_name, now, file_description= filename_format_log(file_path = '../assets/lyric_y74.pkl')\n",
    "\n",
    "# with open(formatted_name, 'wb+') as f:\n",
    "#     pickle.dump(y, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
