{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json, time, re, string, keras, adanet, pickle\n",
    "import pandas as pd\n",
    "import psycopg2 as pg2\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "from numpy import random\n",
    "from psycopg2.extras import RealDictCursor, Json\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding, LSTM\n",
    "from keras.utils.np_utils import to_categorical\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "%run ../assets/sql_cred.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filename_format_log(file_path, \n",
    "                        logfile = '../assets/file_log.txt', \n",
    "                        now = round(time.time()), \n",
    "                        file_description = None): \n",
    "   \n",
    "    try:\n",
    "        ext = re.search('(?<!^)(?<!\\.)\\.(?!\\.)', file_path).start() \n",
    "    except:\n",
    "        raise NameError('Please enter a relative path with a file extension.') \n",
    "    \n",
    "    stamp = re.search('(?<!^)(?<!\\.)[0-z]+_[0-z]+(?=\\.)', file_path).start()\n",
    "    formatted_name = f'{file_path[:stamp]}{now}_{file_path[stamp:]}'  \n",
    "    if not file_description:\n",
    "        file_description = f'Saved at: {time.asctime(time.gmtime(now))}'\n",
    "    with open(logfile, 'a+') as f:\n",
    "        f.write(f'{formatted_name}: {file_description}\\n')\n",
    "    return formatted_name, now, file_description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def con_cur_to_db(dbname=DBNAME, dict_cur=None):\n",
    "    con = pg2.connect(host=IP_ADDRESS,\n",
    "                  dbname=dbname,\n",
    "                  user=USER,\n",
    "                  password=PASSWORD)\n",
    "    if dict_cur:\n",
    "        cur = con.cursor(cursor_factory=RealDictCursor)\n",
    "    else:\n",
    "        cur = con.cursor()\n",
    "    return con, cur\n",
    "    \n",
    "def execute_query(query, dbname=DBNAME, dict_cur=None, command=False):\n",
    "    con, cur = con_cur_to_db(dbname, dict_cur)\n",
    "    cur.execute(f'{query}')\n",
    "    if not command:\n",
    "        data = cur.fetchall()\n",
    "        con.close()\n",
    "        return data\n",
    "    con.commit() #sends to server\n",
    "    con.close() #closes server connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "lyric_df = pd.read_csv('../assets/1548873539_clean_lyrics.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lyrics</th>\n",
       "      <th>clean_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\\n\\nIf your needle is near\\nNeedle is near\\nYo...</td>\n",
       "      <td>if your needle is near \\n needle is near \\n yo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\\n\\n[Verse 1]\\nBrown skin girl on the other si...</td>\n",
       "      <td>brown skin girl on the other side of the room ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\\n\\n[Verse 1]\\nIt's simple, I love it\\nHaving ...</td>\n",
       "      <td>its simple i love it \\n having you near me hav...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\\n\\n[Intro: Whistling]\\n\\n[Verse 1]\\nA great b...</td>\n",
       "      <td>a great big bang and dinosaurs \\n fiery rainin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\\n\\n[Verse 1]\\nIsn't she lovely\\nIsn't she won...</td>\n",
       "      <td>isnt she lovely \\n isnt she wonderful \\n isnt ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              lyrics  \\\n",
       "0  \\n\\nIf your needle is near\\nNeedle is near\\nYo...   \n",
       "1  \\n\\n[Verse 1]\\nBrown skin girl on the other si...   \n",
       "2  \\n\\n[Verse 1]\\nIt's simple, I love it\\nHaving ...   \n",
       "3  \\n\\n[Intro: Whistling]\\n\\n[Verse 1]\\nA great b...   \n",
       "4  \\n\\n[Verse 1]\\nIsn't she lovely\\nIsn't she won...   \n",
       "\n",
       "                                          clean_text  \n",
       "0  if your needle is near \\n needle is near \\n yo...  \n",
       "1  brown skin girl on the other side of the room ...  \n",
       "2  its simple i love it \\n having you near me hav...  \n",
       "3  a great big bang and dinosaurs \\n fiery rainin...  \n",
       "4  isnt she lovely \\n isnt she wonderful \\n isnt ...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lyric_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "lyric_df = lyric_df.drop(index=[193], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lyrics</th>\n",
       "      <th>clean_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1800</td>\n",
       "      <td>1800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>1800</td>\n",
       "      <td>1800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>\\n\\nAnd I wake up today\\nAnd I’m feeling so go...</td>\n",
       "      <td>i wont go livin in the past \\n but i believe t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   lyrics  \\\n",
       "count                                                1800   \n",
       "unique                                               1800   \n",
       "top     \\n\\nAnd I wake up today\\nAnd I’m feeling so go...   \n",
       "freq                                                    1   \n",
       "\n",
       "                                               clean_text  \n",
       "count                                                1800  \n",
       "unique                                               1800  \n",
       "top     i wont go livin in the past \\n but i believe t...  \n",
       "freq                                                    1  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lyric_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:1: UserWarning: This pattern has match groups. To actually get the groups, use str.extract.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lyrics</th>\n",
       "      <th>clean_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>\\n\\n3/3\\nBoy Rex - The Bloodmonths - 8/8\\nJoey...</td>\n",
       "      <td>boy rex  the bloodmonths   \\n joey fatts  ill ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>\\n\\n[Verse 1]\\nJenny, Jenny, who can I turn to...</td>\n",
       "      <td>jenny jenny who can i turn to \\n you give me s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>\\n\\n[NEW]  1. TWICE - What Is Love?\\n[NEW] 2. ...</td>\n",
       "      <td>twice  what is love \\n   exocbx  blooming day ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>260</th>\n",
       "      <td>\\n\\n[Verse 1]:\\nElectric lights\\nBlow my mind\\...</td>\n",
       "      <td>electric lights \\n blow my mind \\n i feel alri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>552</th>\n",
       "      <td>\\n\\nBaby, baby yea\\nYou run on my mind yea\\nSa...</td>\n",
       "      <td>baby baby yea \\n you run on my mind yea \\n sam...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>938</th>\n",
       "      <td>\\n\\n[Verse 1]\\nThere are two of us on the run\\...</td>\n",
       "      <td>there are two of us on the run \\n going so fas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>960</th>\n",
       "      <td>\\n\\n[Verse 1]\\nYou're my baby, my lover, my la...</td>\n",
       "      <td>youre my baby my lover my lady \\n all night yo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1106</th>\n",
       "      <td>\\n\\nORIGINALTracklist1.  Let's Go Crazy\\n2.  T...</td>\n",
       "      <td>originaltracklist  lets go crazy \\n   take me ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1169</th>\n",
       "      <td>\\n\\n[Intro-Live Acoustic]\\nKnow your place amo...</td>\n",
       "      <td>know your place among the dark arms of the woo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1495</th>\n",
       "      <td>\\n\\n[Verse 1]\\nIt was a day\\nJust like any oth...</td>\n",
       "      <td>it was a day \\n just like any other day \\n i w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1545</th>\n",
       "      <td>\\n\\n[Intro: Too $hort]\\nYou know, it's a hard ...</td>\n",
       "      <td>you know its a hard pill to swallow \\n when th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1572</th>\n",
       "      <td>\\n\\n[Verse 1]\\nWrapped up, so consumed by\\nAll...</td>\n",
       "      <td>wrapped up so consumed by \\n all this hurt \\n ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1688</th>\n",
       "      <td>\\n\\n[Intro: Britt Nicole]\\nIt feels like a tea...</td>\n",
       "      <td>it feels like a tear in my heart \\n like a par...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1768</th>\n",
       "      <td>\\n\\nहाथ में रात ये बाकी है\\nबात नापाक वफ़ा की ह...</td>\n",
       "      <td>bang like a drum work my body \\n   im incharge...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 lyrics  \\\n",
       "31    \\n\\n3/3\\nBoy Rex - The Bloodmonths - 8/8\\nJoey...   \n",
       "142   \\n\\n[Verse 1]\\nJenny, Jenny, who can I turn to...   \n",
       "195   \\n\\n[NEW]  1. TWICE - What Is Love?\\n[NEW] 2. ...   \n",
       "260   \\n\\n[Verse 1]:\\nElectric lights\\nBlow my mind\\...   \n",
       "552   \\n\\nBaby, baby yea\\nYou run on my mind yea\\nSa...   \n",
       "938   \\n\\n[Verse 1]\\nThere are two of us on the run\\...   \n",
       "960   \\n\\n[Verse 1]\\nYou're my baby, my lover, my la...   \n",
       "1106  \\n\\nORIGINALTracklist1.  Let's Go Crazy\\n2.  T...   \n",
       "1169  \\n\\n[Intro-Live Acoustic]\\nKnow your place amo...   \n",
       "1495  \\n\\n[Verse 1]\\nIt was a day\\nJust like any oth...   \n",
       "1545  \\n\\n[Intro: Too $hort]\\nYou know, it's a hard ...   \n",
       "1572  \\n\\n[Verse 1]\\nWrapped up, so consumed by\\nAll...   \n",
       "1688  \\n\\n[Intro: Britt Nicole]\\nIt feels like a tea...   \n",
       "1768  \\n\\nहाथ में रात ये बाकी है\\nबात नापाक वफ़ा की ह...   \n",
       "\n",
       "                                             clean_text  \n",
       "31    boy rex  the bloodmonths   \\n joey fatts  ill ...  \n",
       "142   jenny jenny who can i turn to \\n you give me s...  \n",
       "195   twice  what is love \\n   exocbx  blooming day ...  \n",
       "260   electric lights \\n blow my mind \\n i feel alri...  \n",
       "552   baby baby yea \\n you run on my mind yea \\n sam...  \n",
       "938   there are two of us on the run \\n going so fas...  \n",
       "960   youre my baby my lover my lady \\n all night yo...  \n",
       "1106  originaltracklist  lets go crazy \\n   take me ...  \n",
       "1169  know your place among the dark arms of the woo...  \n",
       "1495  it was a day \\n just like any other day \\n i w...  \n",
       "1545  you know its a hard pill to swallow \\n when th...  \n",
       "1572  wrapped up so consumed by \\n all this hurt \\n ...  \n",
       "1688  it feels like a tear in my heart \\n like a par...  \n",
       "1768  bang like a drum work my body \\n   im incharge...  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lyric_df[lyric_df['clean_text'].str.contains(r'(\\s{6,})')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "lyric_df = lyric_df.drop(index=1768, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_sequence(text, sequence_length = 7, output_length = 4):\n",
    "    \n",
    "    X, y = [], []\n",
    "    \n",
    "    split_text = re.split('(\\n)|(\\[.+\\])|\\s', text)\n",
    "    split_text = list(filter(None, split_text))\n",
    "    split_text = text\n",
    "    \n",
    "    for i in range(len(split_text) - sequence_length):\n",
    "        X.append(split_text[i:i + sequence_length])\n",
    "        y.append(split_text[i + sequence_length:i + sequence_length + output_length])\n",
    "        \n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing lyrics...\n",
      "Creating encoding dicts from corpus...\n"
     ]
    }
   ],
   "source": [
    "# tokenize_lyrics(\n",
    "df=lyric_df\n",
    "lyrics_col=['clean_text']\n",
    "seq_len=4 \n",
    "output_len=1\n",
    "save_dir='../assets'\n",
    "# )\n",
    "\n",
    "X = []\n",
    "y = []\n",
    "\n",
    "corpus = []\n",
    "\n",
    "print('Processing lyrics...')\n",
    "for _, track in df[lyrics_col].iterrows():\n",
    "    lyrics = track[0]\n",
    "    lyrics_spaced = re.sub(r'( +)', ' ', lyrics)\n",
    "    lyrics_split = lyrics_spaced.split(' ')\n",
    "    corpus.extend(lyrics_split)\n",
    "\n",
    "    for i in range(len(lyrics_split) - seq_len):\n",
    "        X.append(np.array(lyrics_split[i:i + seq_len]))\n",
    "        y.extend(np.array(lyrics_split[i + seq_len:i + seq_len + output_len]))\n",
    "\n",
    "print('Creating encoding dicts from corpus...')\n",
    "words = sorted(list(set(corpus)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count of unique words (i.e., features): 13468\n"
     ]
    }
   ],
   "source": [
    "print(f'Count of unique words (i.e., features): {len(words)}')\n",
    "words_index = dict((c, i+1) for i, c in enumerate(words))\n",
    "index_words = dict((i+1, c) for i, c in enumerate(words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#         formatted_name, now, file_description= filename_format_log(f'{save_dir}/tokenizer.pkl')\n",
    "\n",
    "#         with open(formatted_name, 'wb+') as f:\n",
    "#             pickle.dump(tokenizer, f)\n",
    "#         print(f'Tokenizer saved to {formatted_name}.')          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indexing sequences...\n",
      "Number of sequences\n",
      "Partitioning and converting to labels...\n"
     ]
    }
   ],
   "source": [
    "print('Indexing sequences...')\n",
    "X_indexed = [[words_index[word] for word in row] for row in X]\n",
    "y_indexed = [words_index[word]for word in y]\n",
    "print('Number of sequences')\n",
    "print('Partitioning and converting to labels...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lyrics successfully tokenized, sequenced, and indexed.\n"
     ]
    }
   ],
   "source": [
    "#     partition, labels = generate_samples(X_indexed, y_indexed)\n",
    "\n",
    "#     np.save(f'{save_dir}/data.npy', partition)\n",
    "X_reshape = np.reshape(X_indexed, (len(X_indexed), seq_len))\n",
    "\n",
    "y_cat = to_categorical(y_indexed)\n",
    "\n",
    "print('Lyrics successfully tokenized, sequenced, and indexed.') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_samples(X_indexed, y_cat, seq_len=4, random_seed = 42):\n",
    "    X_train = [] \n",
    "    X_test = []\n",
    "    y_train = []\n",
    "    y_test = []\n",
    "    \n",
    "    rand_ind = random.choice(range(len(X_indexed)), len(X_indexed), replace=False)\n",
    "    \n",
    "    train_ind = rand_ind[:int(np.ceil(len(rand_ind)*.8))]\n",
    "    test_ind = rand_ind[-int(np.ceil(len(rand_ind)*.2))+1:]\n",
    "\n",
    "    for i in train_ind:\n",
    "        X_train.append(X_indexed[i])\n",
    "        y_train.append(y_cat[i])\n",
    "        \n",
    "    for i in test_ind:\n",
    "        X_test.append(X_indexed[i])\n",
    "        y_test.append(y_cat[i])\n",
    "        \n",
    "    return np.reshape(X_train, (len(X_train), seq_len, 1)) , np.reshape(X_test, (len(X_test), seq_len, 1)), np.array(y_train), np.array(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = generate_samples(X_indexed, y_cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(X_reshape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(576641, 4, 1)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_reshape.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(y_cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile model\n",
    "model = Sequential()\n",
    "model.add(Embedding(len(words)+1, 3000, mask_zero=True))\n",
    "model.add(LSTM(150, return_sequences=True))\n",
    "model.add(LSTM(50))\n",
    "model.add(Dense(100, activation='relu'))\n",
    "model.add(Dense(y_cat.shape[1], activation='softmax'))\n",
    "\n",
    "model.compile(\n",
    "    loss = 'categorical_crossentropy',\n",
    "    optimizer = 'adam',\n",
    "    metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "  2400/576641 [..............................] - ETA: 4:25:13 - loss: 7.6608 - acc: 0.1125"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-34-4bb1b74f83ff>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m model.fit(X_reshape,\n\u001b[1;32m      3\u001b[0m           \u001b[0my_cat\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m           \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m          )\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1040\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1439\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1440\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Train model on dataset\n",
    "model.fit(X_reshape,\n",
    "          y_cat,\n",
    "          verbose=1,\n",
    "         )\n",
    "\n",
    "# Save model\n",
    "# formatted_name, now, file_description= filename_format_log('../assets/LSTM_Model.pkl')\n",
    "\n",
    "# with open(formatted_name, 'wb+') as f:\n",
    "#     pickle.dump(model, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print model summary\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit (\n",
    "    X_train, y_train,\n",
    "    epochs = 150,\n",
    "    batch_size = 2500,\n",
    "    verbose = 1,\n",
    "    \n",
    ")\n",
    "\n",
    "# formatted_name, now, file_description= filename_format_log('../assets/LSTM_Model.pkl')\n",
    "\n",
    "# with open(formatted_name, 'wb+') as f:\n",
    "#     pickle.dump(model, f)\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(ncols=2, nrows=1, figsize=(18,6))\n",
    "\n",
    "ax[0].plot(history.history['loss'])\n",
    "ax[0].set_title(\"Loss\", fontsize=15);\n",
    "ax[0].set_xlabel(\"epochs\",fontsize=15);\n",
    "\n",
    "ax[1].plot(history.history['acc'])\n",
    "ax[1].set_title(\"Accuracy\",fontsize=15);\n",
    "ax[1].set_xlabel(\"epochs\",fontsize=15);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_lyrics(seed, model=model, seq_len=4, song_len=50):\n",
    "    seed_clean = seed.lower().split(' ')\n",
    "    doc = []\n",
    "\n",
    "    while len(doc) < song_len:\n",
    "        text = [seed_clean]\n",
    "        sequence = [tokenizer.texts_to_sequences([word])[0] for word in text]\n",
    "        pad_sequence = pad_sequences(sequence, maxlen=seq_len, truncating='pre')\n",
    "        sequence_reshape = np.reshape(pad_sequence, (len(test_indexed), 4, 1))\n",
    "\n",
    "        yhat = model.predict_classes(sequence_reshape, verbose=0)\n",
    "\n",
    "        for word, index in tokenizer.word_index.items():\n",
    "            if index == yhat:\n",
    "                seed_clean.append(word)\n",
    "                doc.append(word)\n",
    "\n",
    "    return ' '.join(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lyrics = generate_lyrics('needles are for lovers', song_len=150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lyrics"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
